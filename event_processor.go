package ldclient

import (
	"bytes"
	"encoding/json"
	"io/ioutil"
	"math/rand"
	"net/http"
	"sync"
	"sync/atomic"
	"time"
)

type EventProcessor interface {
	// Records an event asynchronously.
	SendEvent(Event)
	// Specifies that any buffered events should be sent as soon as possible, rather than waiting
	// for the next flush interval. This method is asynchronous, so events still may not be sent
	// until a later time.
	Flush()
	// Shuts down all event processor activity, after first ensuring that all events have been
	// delivered. Subsequent calls to SendEvent() or Flush() will be ignored.
	Close() error
}

type nullEventProcessor struct{}

type defaultEventProcessor struct {
	inputCh   chan eventDispatcherMessage
	closeOnce sync.Once
}

type eventDispatcher struct {
	sdkKey            string
	config            Config
	lastKnownPastTime uint64
	disabled          int32 // Really a bool, but there's no atomic bool
}

type eventBuffer struct {
	events           []interface{}
	summarizer       eventSummarizer
	capacity         int
	capacityExceeded bool
	logger           Logger
}

type flushPayload struct {
	events  []interface{}
	summary eventSummary
}

type sendEventsTask struct {
	client           *http.Client
	eventsUri        string
	logger           Logger
	sdkKey           string
	userAgent        string
	userFilter       userFilter
	inlineUsers      bool
	responseListener func(*http.Response)
}

// Payload of the inputCh channel.
type eventDispatcherMessage interface{}

type sendEventMessage struct {
	event Event
}

type flushEventsMessage struct{}

type shutdownEventsMessage struct {
	replyCh chan struct{}
}

type syncEventsMessage struct {
	replyCh chan struct{}
}

// Serializable form of a feature request event. This differs from the event that was
// passed in to us in that it has a user key instead of a user object, and it only shows
// the flag value, not the variation index.
type featureRequestEventOutput struct {
	Kind         string      `json:"kind"`
	CreationDate uint64      `json:"creationDate"`
	Key          string      `json:"key"`
	UserKey      *string     `json:"userKey,omitempty"`
	User         *User       `json:"user,omitempty"`
	Value        interface{} `json:"value"`
	Default      interface{} `json:"default"`
	Version      *int        `json:"version,omitempty"`
	PrereqOf     *string     `json:"prereqOf,omitempty"`
}

// Serializable form of an identify event.
type identifyEventOutput struct {
	Kind         string  `json:"kind"`
	CreationDate uint64  `json:"creationDate"`
	Key          *string `json:"key"`
	User         *User   `json:"user"`
}

// Serializable form of a custom event. It has a user key instead of a user object.
type customEventOutput struct {
	Kind         string      `json:"kind"`
	CreationDate uint64      `json:"creationDate"`
	Key          string      `json:"key"`
	UserKey      *string     `json:"userKey,omitempty"`
	User         *User       `json:"user,omitempty"`
	Data         interface{} `json:"data,omitempty"`
}

// Serializable form of an index event. This is not generated by an explicit client call,
// but is created automatically whenever we see a user we haven't seen before in a feature
// request event or custom event.
type indexEventOutput struct {
	Kind         string `json:"kind"`
	CreationDate uint64 `json:"creationDate"`
	User         *User  `json:"user"`
}

// Serializable form of a summary event, containing data generated by EventSummarizer.
type summaryEventOutput struct {
	Kind      string                     `json:"kind"`
	StartDate uint64                     `json:"startDate"`
	EndDate   uint64                     `json:"endDate"`
	Features  map[string]flagSummaryData `json:"features"`
}

const (
	FEATURE_REQUEST_EVENT = "feature"
	FEATURE_DEBUG_EVENT   = "debug"
	CUSTOM_EVENT          = "custom"
	IDENTIFY_EVENT        = "identify"
	INDEX_EVENT           = "index"
	SUMMARY_EVENT         = "summary"
	maxFlushWorkers       = 5
)

func newNullEventProcessor() *nullEventProcessor {
	return &nullEventProcessor{}
}

func (n *nullEventProcessor) SendEvent(e Event) {}

func (n *nullEventProcessor) Flush() {}

func (n *nullEventProcessor) Close() error {
	return nil
}

func newDefaultEventProcessor(sdkKey string, config Config, client *http.Client) *defaultEventProcessor {
	if client == nil {
		client = &http.Client{}
	}
	inputCh := make(chan eventDispatcherMessage, config.Capacity)
	startEventDispatcher(sdkKey, config, client, inputCh)
	return &defaultEventProcessor{
		inputCh: inputCh,
	}
}

func (ep *defaultEventProcessor) SendEvent(e Event) {
	ep.inputCh <- sendEventMessage{event: e}
}

func (ep *defaultEventProcessor) Flush() {
	ep.inputCh <- flushEventsMessage{}
}

func (ep *defaultEventProcessor) Close() error {
	ep.closeOnce.Do(func() {
		ep.inputCh <- flushEventsMessage{}
		m := shutdownEventsMessage{replyCh: make(chan struct{})}
		ep.inputCh <- m
		<-m.replyCh
	})
	return nil
}

// used only for testing - ensures that all pending messages and flushes have completed
func (ep *defaultEventProcessor) waitUntilInactive() {
	m := syncEventsMessage{replyCh: make(chan struct{})}
	ep.inputCh <- m
	<-m.replyCh // Now we know that all events prior to this call have been processed
}

func startEventDispatcher(sdkKey string, config Config, client *http.Client,
	inputCh chan eventDispatcherMessage) {
	ed := &eventDispatcher{
		sdkKey: sdkKey,
		config: config,
	}

	// Start a fixed-size pool of workers that wait on flushTriggerCh. This is the
	// maximum number of flushes we can do concurrently.
	flushCh := make(chan *flushPayload, 1)
	var workersGroup sync.WaitGroup
	for i := 0; i < maxFlushWorkers; i++ {
		startFlushTask(sdkKey, config, client, flushCh, &workersGroup,
			func(r *http.Response) { ed.handleResponse(r) })
	}
	go ed.runMainLoop(inputCh, flushCh, &workersGroup)
}

func (ed *eventDispatcher) runMainLoop(inputCh chan eventDispatcherMessage,
	flushCh chan *flushPayload, workersGroup *sync.WaitGroup) {
	if err := recover(); err != nil {
		ed.config.Logger.Printf("Unexpected panic in event processing thread: %+v", err)
	}

	buffer := eventBuffer{
		events:     make([]interface{}, 0, ed.config.Capacity),
		summarizer: newEventSummarizer(),
		capacity:   ed.config.Capacity,
		logger:     ed.config.Logger,
	}
	userKeys := newLruCache(ed.config.UserKeysCapacity)

	flushInterval := ed.config.FlushInterval
	if flushInterval <= 0 {
		flushInterval = DefaultConfig.FlushInterval
	}
	userKeysFlushInterval := ed.config.UserKeysFlushInterval
	if userKeysFlushInterval <= 0 {
		userKeysFlushInterval = DefaultConfig.UserKeysFlushInterval
	}
	flushTicker := time.NewTicker(flushInterval)
	usersResetTicker := time.NewTicker(userKeysFlushInterval)

	for {
		select {
		case message := <-inputCh:
			switch m := message.(type) {
			case sendEventMessage:
				ed.processEvent(m.event, &buffer, &userKeys)
			case flushEventsMessage:
				ed.triggerFlush(&buffer, flushCh, workersGroup)
			case syncEventsMessage:
				workersGroup.Wait()
				m.replyCh <- struct{}{}
			case shutdownEventsMessage:
				flushTicker.Stop()
				usersResetTicker.Stop()
				workersGroup.Wait() // Wait for all in-progress flushes to complete
				close(flushCh)      // Causes all idle flush workers to terminate
				m.replyCh <- struct{}{}
				return
			}
		case <-flushTicker.C:
			ed.triggerFlush(&buffer, flushCh, workersGroup)
		case <-usersResetTicker.C:
			userKeys.clear()
		}
	}
}

func (ed *eventDispatcher) isDisabled() bool {
	return atomic.LoadInt32(&ed.disabled) != 0
}

func (ed *eventDispatcher) processEvent(evt Event, buffer *eventBuffer, userKeys *lruCache) {
	if ed.isDisabled() {
		return
	}
	// For each user we haven't seen before, we add an index event - unless this is already
	// an identify event for that user.
	if !ed.config.InlineUsersInEvents {
		user := evt.GetBase().User
		if !noticeUser(userKeys, &user) {
			if _, ok := evt.(IdentifyEvent); !ok {
				indexEvent := indexEventOutput{
					Kind:         INDEX_EVENT,
					CreationDate: evt.GetBase().CreationDate,
					User:         &user,
				}
				buffer.queueEvent(indexEvent)
			}
		}
	}

	// Always record the event in the summarizer.
	buffer.addToSummary(evt)

	if ed.shouldTrackFullEvent(evt) {
		// Sampling interval applies only to fully-tracked events.
		if ed.config.SamplingInterval == 0 || rand.Int31n(ed.config.SamplingInterval) == 0 {
			// Queue the event as-is; we'll transform it into an output event when we're flushing
			// (to avoid doing that work on our main goroutine).
			buffer.queueEvent(evt)
		}
	}
}

// Add to the set of users we've noticed, and return true if the user was already known to us.
func noticeUser(userKeys *lruCache, user *User) bool {
	if user == nil || user.Key == nil {
		return true
	}
	return userKeys.add(*user.Key)
}

func (ed *eventDispatcher) shouldTrackFullEvent(evt Event) bool {
	switch evt := evt.(type) {
	case FeatureRequestEvent:
		if evt.TrackEvents {
			return true
		}
		if evt.DebugEventsUntilDate != nil {
			// The "last known past time" comes from the last HTTP response we got from the server.
			// In case the client's time is set wrong, at least we know that any expiration date
			// earlier than that point is definitely in the past.  If there's any discrepancy, we
			// want to err on the side of cutting off event debugging sooner.
			lastPast := atomic.LoadUint64(&ed.lastKnownPastTime)
			if *evt.DebugEventsUntilDate > lastPast &&
				*evt.DebugEventsUntilDate > now() {
				return true
			}
		}
		return false
	default:
		// Custom and identify events are always included in full
		return true
	}
}

// Signal that we would like to do a flush as soon as possible.
func (ed *eventDispatcher) triggerFlush(buffer *eventBuffer, flushCh chan *flushPayload,
	workersGroup *sync.WaitGroup) {
	if ed.isDisabled() {
		return
	}
	// Is there anything to flush?
	summary := buffer.summarizer.snapshot()
	if len(buffer.events) == 0 && len(summary.counters) == 0 {
		return
	}
	payload := flushPayload{
		events:  buffer.events,
		summary: summary,
	}
	workersGroup.Add(1) // Increment the count of active flushes
	select {
	case flushCh <- &payload:
		// If the channel wasn't full, then there is a worker available who will pick up
		// this flush payload and send it. The event buffer and summary state can now be
		// cleared from the main goroutine.
		buffer.clear()
	default:
		// We can't start a flush right now because we're waiting for one of the workers
		// to pick up the last one.  Do not reset the event buffer or summary state.
		workersGroup.Done()
	}
}

func (ed *eventDispatcher) handleResponse(resp *http.Response) {
	err := checkStatusCode(resp.StatusCode, resp.Request.URL.String())
	if err != nil {
		ed.config.Logger.Printf("Unexpected status code when sending events: %+v", err)
		if err != nil && err.Code == 401 {
			ed.config.Logger.Printf("Received 401 error, no further events will be posted since SDK key is invalid")
			atomic.StoreInt32(&ed.disabled, 1)
		}
	} else {
		dt, err := http.ParseTime(resp.Header.Get("Date"))
		if err == nil {
			tm := toUnixMillis(dt)
			atomic.StoreUint64(&ed.lastKnownPastTime, tm)
		}
	}
}

func (b *eventBuffer) queueEvent(event interface{}) {
	if len(b.events) >= b.capacity {
		if !b.capacityExceeded {
			b.capacityExceeded = true
			b.logger.Printf("WARN: Exceeded event queue capacity. Increase capacity to avoid dropping events.")
		}
	} else {
		b.capacityExceeded = false
		b.events = append(b.events, event)
	}
}

func (b *eventBuffer) addToSummary(event Event) {
	b.summarizer.summarizeEvent(event)
}

func (b *eventBuffer) clear() {
	b.events = make([]interface{}, 0, b.capacity)
	b.summarizer.reset()
}

func startFlushTask(sdkKey string, config Config, client *http.Client, flushCh chan *flushPayload,
	workersGroup *sync.WaitGroup, responseListener func(*http.Response)) {
	t := sendEventsTask{
		client:           client,
		eventsUri:        config.EventsUri + "/bulk",
		logger:           config.Logger,
		sdkKey:           sdkKey,
		userAgent:        config.UserAgent,
		userFilter:       newUserFilter(config),
		inlineUsers:      config.InlineUsersInEvents,
		responseListener: responseListener,
	}
	go t.run(flushCh, workersGroup)
}

func (t *sendEventsTask) run(flushCh chan *flushPayload, workersGroup *sync.WaitGroup) {
	for {
		payload, more := <-flushCh
		if !more {
			// Channel has been closed - we're shutting down
			break
		}
		outputEvents := t.makeOutputEvents(payload)
		if len(outputEvents) > 0 {
			resp := t.postEvents(outputEvents)
			if resp != nil {
				t.responseListener(resp)
			}
		}
		workersGroup.Done() // Decrement the count of in-progress flushes
	}
}

func (t *sendEventsTask) makeOutputEvents(payload *flushPayload) []interface{} {
	out := make([]interface{}, 0, len(payload.events)+1) // leave room for summary, if any
	for _, e := range payload.events {
		oe := t.makeOutputEvent(e)
		if oe != nil {
			out = append(out, oe)
		}
	}
	if len(payload.summary.counters) > 0 {
		out = append(out, t.makeSummaryEvent(payload.summary))
	}
	return out
}

func (t *sendEventsTask) postEvents(outputEvents []interface{}) *http.Response {
	jsonPayload, marshalErr := json.Marshal(outputEvents)
	if marshalErr != nil {
		t.logger.Printf("Unexpected error marshalling event json: %+v", marshalErr)
		return nil
	}

	req, reqErr := http.NewRequest("POST", t.eventsUri, bytes.NewReader(jsonPayload))
	if reqErr != nil {
		t.logger.Printf("Unexpected error while creating event request: %+v", reqErr)
		return nil
	}

	req.Header.Add("Authorization", t.sdkKey)
	req.Header.Add("Content-Type", "application/json")
	req.Header.Add("User-Agent", t.userAgent)

	resp, respErr := t.client.Do(req)

	defer func() {
		if resp != nil && resp.Body != nil {
			ioutil.ReadAll(resp.Body)
			resp.Body.Close()
		}
	}()

	if respErr != nil {
		t.logger.Printf("Unexpected error while sending events: %+v", respErr)
		return nil
	}
	return resp
}

func (t *sendEventsTask) makeOutputEvent(evt interface{}) interface{} {
	switch evt := evt.(type) {
	case FeatureRequestEvent:
		fe := featureRequestEventOutput{
			CreationDate: evt.BaseEvent.CreationDate,
			Key:          evt.Key,
			Value:        evt.Value,
			Default:      evt.Default,
			Version:      evt.Version,
			PrereqOf:     evt.PrereqOf,
		}
		if t.inlineUsers {
			fe.User = t.userFilter.scrubUser(evt.User)
		} else {
			fe.UserKey = evt.User.Key
		}
		if !evt.TrackEvents && evt.DebugEventsUntilDate != nil {
			fe.Kind = FEATURE_DEBUG_EVENT
		} else {
			fe.Kind = FEATURE_REQUEST_EVENT
		}
		return fe
	case CustomEvent:
		ce := customEventOutput{
			Kind:         CUSTOM_EVENT,
			CreationDate: evt.BaseEvent.CreationDate,
			Key:          evt.Key,
			Data:         evt.Data,
		}
		if t.inlineUsers {
			ce.User = t.userFilter.scrubUser(evt.User)
		} else {
			ce.UserKey = evt.User.Key
		}
		return ce
	case IdentifyEvent:
		return identifyEventOutput{
			Kind:         IDENTIFY_EVENT,
			CreationDate: evt.BaseEvent.CreationDate,
			Key:          evt.User.Key,
			User:         t.userFilter.scrubUser(evt.User),
		}
	case indexEventOutput:
		evt.User = t.userFilter.scrubUser(*evt.User)
		return evt
	default:
		t.logger.Printf("Found unknown event type in output queue: %T", evt)
		return nil
	}
}

// Transforms the summary data into the format used for event sending.
func (t *sendEventsTask) makeSummaryEvent(snapshot eventSummary) summaryEventOutput {
	features := make(map[string]flagSummaryData)
	for key, value := range snapshot.counters {
		var flagData flagSummaryData
		var known bool
		if flagData, known = features[key.key]; !known {
			flagData = flagSummaryData{
				Default:  value.flagDefault,
				Counters: make([]flagCounterData, 0, 2),
			}
		}
		data := flagCounterData{
			Value: value.flagValue,
			Count: value.count,
		}
		if key.version == 0 {
			unknown := true
			data.Unknown = &unknown
		} else {
			version := key.version
			data.Version = &version
		}
		flagData.Counters = append(flagData.Counters, data)
		features[key.key] = flagData
	}

	return summaryEventOutput{
		Kind:      "summary",
		StartDate: snapshot.startDate,
		EndDate:   snapshot.endDate,
		Features:  features,
	}
}
